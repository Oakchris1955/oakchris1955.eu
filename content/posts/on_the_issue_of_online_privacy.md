---
title: On the issue of online privacy regarding recent
       developments on Youtube's age verification and EU's Chat Control
date: 2025-08-10T15:52:11+0300
---

This article will cover two very important recent developments in the tech world.
One of them concerns EU's Chat Control proposal, which has been proposed and rejected
numerous times until now but somehow keeps coming back, while the other will cover
the intention of Youtube to roll a form of age verification powered by AI.
Both of these changes are very concerning in my opinion and should be mentioned
more by mainstream media, which instead turn their spotlights in Alaska for the
upcoming Trump-Putin meeting regarding Ukraine, as if anything fruitful will
come out of that.

## Courage firm in grievous trial, help, where innocence doth scream - Ode to Joy

We are living through a challenging period for United Europe as a concept.
Yet, despite the many external dangers to Europe's integrity, more and more
internal dangers seem to arise from day-to-day. One of them is the so-called
Chat Control proposal. On its surface, it seems like a good idea: we need to
prevent the children from the dangers of the Internet. Alright, so, how do we
do that? We could tell parents to inform children about the dangerous nature
of the Internet (which they probably should already do on their own). How about
teaching them on school during Computer Science? (yes, I know that is already
being done on some countries, but in my country that's usually 1-2 hours
per year, although the CS subject in Greece is generally not thought of as
an important one for the majority of primary and secondary education)
Wait, what do you mean the proposed solution is to spy on all online communications?

### There was of course no way of knowing whether you were being watched at any given momen - 1984

While we can all agree that we need to protect the children from the Internet,
what they have been trying to implement for the past 2-3 years is in no way suitable for that cause.
The regulation essentially proposes spying on all online communications, which is
not online morally incorrect most people would say, but also impossible to actually
enforce. In case the perpetrator lives within the European Union, it would be
relatively easy to arrest them. But the Internet is worldwide, which means
that even if Europe could cooperate with the local police to arrest them, it would
require the surveillance of not just all European communication, thus preparing
the ground for similar legislations in other countries and making everyday
online surveillance the norm in the entire world in the long term.

### Is it even feasible?

According to [PCMag](https://www.pcmag.com/news/what-happens-in-60-seconds-of-global-internet-activity),
within a minute Instagram users send ~700k reels via DMs. There is no possible way
that many messages can be handled by humans: automation of some sort will have to be implemented.
Let's also assume that users send ~50% that volume of personal texts
during that same time period, so ~350k. Assuming that the majority (99,9%) of them
aren't what Chat Control wants to prevent children from, and with a 0.01% false positive rate,
that would amount to 35 false positives per minute. That's just Instagram DMs:
there are dozens of other platforms out there that have to be covered, as well as
SMS messages and phone calls, all of them will have to be limited too, and false
positives will have to be dealt with. And that's just text: add in the equation
video and images and the numbers just don't sum up.

## Age-estimation just won't work

Youtube is planning to roll out an "age-verification" system for the Americas
on August 13. According to them, the way this will work is that viewers will
be categorized on adults and non-adults depending on the kind of content they
watch. This problem fall within the field of machine learning classification and
there is a huge issue with the plan as proposed: how do we determine who's an adult?

### Single account, multiple users

First things first, let's get the obvious out of the way: viewers that watch channels
such as Cocomelon will probably be assumed to be a kid. But what if that is a shared
account between a parent and their child? (people that young shouldn't even be allowed
by their parents to have access to the Internet, but that's just my opinion).
Does it make sense to have to use age verification just because your kid watches
channels targeted at children? And if you verify that you are an adult, doesn't that
defeat the whole premise of the system, since your kid will now be able to watch
Youtube unrestricted?

### Have you heard of Youtube Kids?

All the way back in 2015, Youtube launched Youtube Kids, which is intended to be
a family-friendly version of Youtube. However, there are still quite a lot of
children-targeted channels that operate on Youtube and not Youtube Kids. Apart from
that, many parents don't even create a separate Kids account for their children, so
why should regular Youtube viewers have to pay the price for those few parents
that in the end don't care to protect their children?

### Artificial borders

I mentioned above some content that is targeted to children-exclusive audiences.
However, there's also content that isn't targeted against a certain audience and
thus can't be used to determine whether the viewer is an adult or not. Take for example
video games like Minecraft, that both children and adults watch. There are 3 possible ways
to handle this kind of content:

1. Mark the content as children-related, bringing up false-positives
2. Mark the content as adult-related, bringing up false-negatives
3. Don't use that content to determine whether the viewer is an adult or not,
   reducing the training data and thus overall accuracy

## Why that much hustle mid-summer season?

I don't understand why everyone, the U.K., the E.U., Youtube, are trying to pass
all these major changes mid-summer, when everyone is in vacation and there is
nobody to oppose such actions. Oh wait...
